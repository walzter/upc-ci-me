{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular PyTorch: Category Embedding Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TAB_utils import prep_tab_df\n",
    "from TAB_Model import MakeCategoryEmbeddingModel, test_model, custom_train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data/CovidCoughDataset.csv'\n",
    "DF, NUM_COL = prep_tab_df(PATH)\n",
    "TARGET_COL ='num_label'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1000\n",
    "LAYERS = '1024-512-512'\n",
    "ACTIVATION_FUNCTION = 'LeakyReLU'\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "# making a training iter \n",
    "batches = [1024]\n",
    "num_epochs = [100, 200]\n",
    "layers = ['512-256-256']\n",
    "ACT_Fs = ['LeakyReLU','ReLU']\n",
    "LEARNING_RATES = [1e-2,1e-3, 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we scale the values \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import pandas as pd\n",
    "pt = PowerTransformer('yeo-johnson',standardize=True)\n",
    "X, Y = DF.iloc[:,:-1], DF.iloc[:,-1]\n",
    "xcols = X.columns \n",
    "Xv = X.values \n",
    "pt.fit(Xv)\n",
    "Xscaled = pt.transform(Xv)\n",
    "\n",
    "df = pd.DataFrame(Xscaled, columns=xcols)\n",
    "df['num_label'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Eric/opt/anaconda3/envs/ci_covid/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f816a2f14c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Eric/opt/anaconda3/envs/ci_covid/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/Eric/opt/anaconda3/envs/ci_covid/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1295, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n",
      "LR finder stopped early after 24 steps due to diverging loss.\n",
      "Restored states from the checkpoint file at /Users/Eric/Documents/Uni/Msc/Courses/Sem1/CI/LAB/covid/models/PyTorch_Tabular/lr_find_temp_model.ckpt\n",
      "Finding best initial lr:  24%|██▍       | 24/100 [08:27<26:45, 21.13s/it]\n",
      "Learning rate set to 7.585775750291837e-08\n",
      "\n",
      "  | Name                   | Type                | Params\n",
      "---------------------------------------------------------------\n",
      "0 | embedding_layers       | ModuleList          | 0     \n",
      "1 | normalizing_batch_norm | BatchNorm1d         | 52    \n",
      "2 | backbone               | FeedForwardBackbone | 210 K \n",
      "3 | output_layer           | Linear              | 514   \n",
      "4 | loss                   | CrossEntropyLoss    | 0     \n",
      "---------------------------------------------------------------\n",
      "211 K     Trainable params\n",
      "0         Non-trainable params\n",
      "211 K     Total params\n",
      "0.846     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/Eric/opt/anaconda3/envs/ci_covid/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/Eric/opt/anaconda3/envs/ci_covid/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/Eric/opt/anaconda3/envs/ci_covid/lib/python3.8/site-packages/torch/__init__.py\", line 197, in <module>\n",
      "    from torch._C import *  # noqa: F403\n",
      "RuntimeError: KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4 [00:00<00:00, -1463.21it/s]  "
     ]
    }
   ],
   "source": [
    "#custom_train_loop(TARGET_COL, NUM_COL,BATCHES, NUM_EPOCHS, NUM_LAYERS, ACT_FUNCS)\n",
    "results_dict = custom_train_loop(df,TARGET_COL,NUM_COL, batches, num_epochs, layers, ACT_Fs,LEARNING_RATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results_dict)\n",
    "df.to_csv('./CEM_1024_pt.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the model \n",
    "CEM_model = MakeCategoryEmbeddingModel(TARGET_COL,\n",
    "                                       NUM_COL,\n",
    "                                       batch_size=BATCH_SIZE,\n",
    "                                       epochs=EPOCHS,\n",
    "                                       auto_find_lr=True,\n",
    "                                       to_use_gpu=None,\n",
    "                                       task='classification',\n",
    "                                       layers=LAYERS,\n",
    "                                       act_f = ACTIVATION_FUNCTION,\n",
    "                                       lr = LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, predictions = test_model(CEM_model,DF,RANDOM_STATE=42, save_model=False, model_name=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6858c3dbc49267e902ff986705b591b9d7b57befff84fd7d814fe16c4a8e1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ci_covid': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
