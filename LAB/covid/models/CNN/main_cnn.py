# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10j2dqItQbZLOnQdUYYxhxfeVSJVSsbdc
"""
# tracking
import wandb
# file utils
import glob, os, shutil
#nice colors
import termcolor
from termcolor import colored
# torch
import torch
# nns
import torch.nn as nn
import torch.nn.functional as F
# dataset making
from torch.utils.data import Dataset, DataLoader
# optimization
import torch.optim as optim
# sklearn
from sklearn.model_selection import train_test_split
# image
from torchvision.io import read_image
import cv2
# dataframe
import pandas as pd
#plotting
import matplotlib.pyplot as plt
# mounting the drive
#from google.colab import drive
#drive.mount('/content/drive')

wandb.config = {
          'BATCH_SIZE':64,
          'EPOCHS':100,
          'TRAIN_RATIO':0.7,
          'LEARNING_RATE':0.01,
          'NUM_CLASSES':2,
          'CHANNELS':3,
          'conv1_filters':32,
          'conv1_kernel':5,
          'convb1_pool':(2,2),
          'conv2_filters':64,
          'convb2_pool':(2,2),
          'conv3_filters':128,
          'conv4_filters':256,
          'adaptive_pool_size':(5,5),
          'linear1_output':500,
          'linear2_output':200,
          'dropout':0.10,
          'N_BATCHES_TEST_STEPS':100,
          }

config = wandb.config
# PATHS
#IMG_PATH = '/content/drive/MyDrive/Notebooks/CI/LAB/Covid/data/Spectrograms'
IMG_PATH = '/Users/Eric/Documents/uni/msc/courses/sem1/ci/lab/covid/main_data/spectrograms'
all_files = glob.glob(IMG_PATH + '/all_images/*')
#all_files = glob.glob(IMG_PATH + '/all_imgs/*')
print(f"\nFound {len(all_files)} Images belonging to two classes\n")
pos_samples = [1 if 'Positive' in x.split('_') else 0 for x in all_files]
pos = sum(pos_samples)
neg = len(all_files) - pos
print(f"There are {pos} Positive Samples\n")
print(f"There are {neg} Negative Samples\n")


# make the splits accordingly 
def train_test_val_split(X_values, Y_values,TRAIN_RATIO=config['TRAIN_RATIO']):
    '''
    Args:
        X_values (Matrix): Features 
        Y_values (Column Vector): Labels
        TRAIN_RATIO (Float): % to split the Data into training - default = 0.70 or 70%
        VALIDATION_RATIO (Float): % to split the data into validation - default = 0.15 or 15%
        TEST_RATIO (Float): % to split the data into testing - default = 0.15 or 15%
    Output:
        Splitting the X_values and the Y_values according to: 
            - train_ratio
            - validation_ratio 
            - test_ratio 
    '''

    # This will use the percentage of the test_size approx to train the values 
    X_train, X_test, Y_train, Y_test = train_test_split(X_values, Y_values, test_size= 1 - TRAIN_RATIO)

    # now we can get the validation set which is going to be 15% of the dataset
    # testing is now 15% of the original dataset 
    #X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size = TEST_RATIO / (TEST_RATIO + VALIDATION_RATIO))

    # grouping them for easier read
    training,testing = (X_train, Y_train),(X_test, Y_test)
            
    return training, testing 

class CovidCoughDatasetSpectrograms(Dataset):
    def __init__(self,label, data):
        self.data = data
        self.label = label

    def __len__(self):
        return len(self.label)

    def __getitem__(self, idx):
        img_path = self.data[idx]
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        #image = cv2.resize(image, (32,32),interpolation=cv2.INTER_AREA)
        image = (image/255.)
        label = self.label[idx]
        return image, label

# prepare the values 
#ANNOTATIONS_FILE = '/content/drive/MyDrive/Notebooks/CI/LAB/Covid/data/Spectrograms/img_labels.csv'
ANNOTATIONS_FILE = '/Users/Eric/Documents/uni/msc/courses/sem1/ci/lab/covid/models/cnn/all_labels.csv'
df = pd.read_csv(ANNOTATIONS_FILE)
df = df.drop('Unnamed: 0',axis=1)
X, Y = df.iloc[:,0].values, df.iloc[:,1].values

#splitting
(X_train, y_train), (X_test, y_test) = train_test_val_split(X, Y, TRAIN_RATIO=0.7)
#(X_train, y_train), (X_val, y_val) = train_test_val_split(X_train, y_train, TRAIN_RATIO=0.7)

# making the dataset 
# Training
train_dataset = CovidCoughDatasetSpectrograms(y_train, X_train)
# Testing
test_dataset = CovidCoughDatasetSpectrograms(y_test, X_test)
# Validation 
#val_dataset = CovidCoughDatasetSpectrograms(y_val, X_val)

# Making the loaders
train_loader = DataLoader(train_dataset, batch_size = config['BATCH_SIZE'], shuffle=True)
test_loader = DataLoader(test_dataset, batch_size = config['BATCH_SIZE'], shuffle=True)
#val_loader = DataLoader(val_dataset, batch_size = 4, shuffle=True)

class NetXConfig(nn.Module):
    def __init__(self):
        super().__init__()
        # block 1
        self.conv1 = nn.Conv2d(config['CHANNELS'], config['conv1_filters'], config['conv1_kernel'])
        self.poolb1 = nn.MaxPool2d(config['convb1_pool'][0], config['convb1_pool'][1])
        self.conv2 = nn.Conv2d(config['conv1_filters'], config['conv2_filters'], config['conv1_kernel'])
        # block 2
        self.conv3 = nn.Conv2d(config['conv2_filters'], config['conv3_filters'], config['conv1_kernel'])
        self.poolb2 = nn.MaxPool2d(config['convb2_pool'][0], config['convb2_pool'][1])
        self.conv4 = nn.Conv2d(config['conv3_filters'], config['conv4_filters'], config['conv1_kernel'])
        self.adapt = nn.AdaptiveAvgPool2d(config['adaptive_pool_size'])
        # linear activation
        self.fc1 = nn.Linear(config['conv4_filters'] * config['adaptive_pool_size'][0]* config['adaptive_pool_size'][1], config['linear1_output'])
        self.fc2 = nn.Linear(config['linear1_output'], config['linear2_output'])
        self.fc3 = nn.Linear(config['linear2_output'], config['NUM_CLASSES'])
        #dropout
        #self.dropout = nn.Dropout(config['dropout'])

    def forward(self, x):
        # block 1
        x = self.poolb1(F.relu(self.conv1(x)))
        x = self.poolb1(F.relu(self.conv2(x)))
        # block 2
        x = self.poolb2(F.relu(self.conv3(x)))
        x = self.poolb2(F.relu(self.conv4(x)))
        # block 3
        #x = self.poolb3(F.relu(self.conv5(x)))
        #x = self.poolb3(F.relu(self.conv6(x)))
        # adapt and flatten
        x = self.adapt(x)
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        x = self.fc1(x) #Shape of Linear layer 1: torch.Size([4, 120])
        x = self.fc2(x) #Shape of Linear layer 2: torch.Size([4, 84])
        #x = self.dropout(x)
        x = self.fc3(x) # Shape of Linear layer 3: torch.Size([4, 2])
        
        return x
# device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# instantiate
net = NetXConfig()
#to cuda
if device.type == 'cuda':
  net = net.cuda()
else:
  net = net.to(device)
# loss and opt
criterion = nn.CrossEntropyLoss()
#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)
optimizer = optim.Adam(net.parameters(), lr=config['LEARNING_RATE'])



def train_test_val():
  #wandb.init(project="ci_lab_covid_cnn", entity="walzter")
  #wandb.watch(net, criterion, log="all", log_freq=1)
  STEP =10
  for EPOCH in range(1,101):
    #wandb.log({"EPOCH":EPOCH})
    # TRAINING THE MODEL
    train_loss = 0.0
    train_correct = 0.0
    # train mode 
    net.train()
    for l, data in enumerate(train_loader, 0):
      inputs, labels = data
      inputs, labels = inputs.to(device), labels.to(device)
      inputs = inputs.permute(0,3,2,1)
      inputs = inputs.float()
      #zeroing the gradients 
      optimizer.zero_grad()
      # Forward + Backwards + Optimization
      outputs = net(inputs)
      outputs = outputs.to(device)
      loss = criterion(outputs, labels)
      # backwards pass
      loss.backward()
      #stepping the optimizer
      optimizer.step()
      # get some feedback from the model
      _, prediction = torch.max(outputs.data,1)
      correct = (prediction == labels).sum().item()
      train_correct += correct
      #getting the loss + accuracy 
      train_loss += loss.item()
      train_acc = (train_correct/(len(train_loader.dataset)))
      #wandb logging
      #wandb.log({"train_acc": train_acc})
      #wandb.log({"train_loss": train_loss})
      #if l % STEP == 0:
      train_text = f"\nTRAINING --> EPOCH: {EPOCH}, STEP: {l + 1}, LOSS: {train_loss/(len(train_loader.dataset))}, ACCURACY: {(train_correct/(len(train_loader.dataset)))*100}"
      print(colored(train_text, 'white','on_red',attrs=['bold']))

    # TESTING
    if EPOCH % 5 == 0: 
      test_loss = 0.0
      test_correct = 0.0
      net.eval()
      for test_l, test_data in enumerate(test_loader,0):
        # putting it into eval mode 
        tinputs, tlabels = test_data
        tinputs, tlabels = tinputs.to(device), tlabels.to(device)
        tinputs = tinputs.permute(0,3,2,1)
        tinputs = tinputs.float() 
        # prediction
        test_pred = net(tinputs)
        test_pred = test_pred.to(device)
        # loss test
        loss_test = criterion(test_pred, tlabels)
        # zeroing the gradients
        optimizer.zero_grad()
        # feedback 
        _, test_pred = torch.max(test_pred.data,1)
        tcorrect = (test_pred == tlabels).sum().item()
        # getting the accuracy & loss
        test_correct+=tcorrect
        test_acc = (test_correct / (len(test_loader.dataset)))
        #logging
        #wandb.log({"test_acc": test_acc})
        #wandb.log({"loss_test": loss_test})
      
        
        #if test_l % config['N_BATCHES_TEST_STEPS'] == 0:
        test_text = f"\nTESTING --> EPOCH: {EPOCH + 1}, STEP: {l + 1}, LOSS: {test_loss/(len(test_loader.dataset))}, ACCURACY: {(test_correct / (len(test_loader.dataset)))*100}"
        print(colored(test_text, 'green','on_grey',attrs=['bold']))

for k,v in config.items():
  print(colored(k, 'red',attrs=['bold']),'-->',colored(v, 'green',attrs=['bold']))


train_test_val()

